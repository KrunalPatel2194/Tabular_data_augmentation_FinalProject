{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "# Network Parameters\n",
    "seed = 123\n",
    "input_nodes = 101\n",
    "output_nodes = 101\n",
    "learning_rate = 0.005\n",
    "num_iterations = 30\n",
    "batch_size = 100\n",
    "weights_folder = '/weights/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>data</th>\n",
       "      <th>timeofday</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-07-01 00:00:00</td>\n",
       "      <td>10844</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-01 00:30:00</td>\n",
       "      <td>8127</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-07-01 01:00:00</td>\n",
       "      <td>6210</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-01 01:30:00</td>\n",
       "      <td>4656</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-07-01 02:00:00</td>\n",
       "      <td>3820</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time   data  timeofday  dayofweek\n",
       "0  2014-07-01 00:00:00  10844          0          1\n",
       "1  2014-07-01 00:30:00   8127         30          1\n",
       "2  2014-07-01 01:00:00   6210         60          1\n",
       "3  2014-07-01 01:30:00   4656         90          1\n",
       "4  2014-07-01 02:00:00   3820        120          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data fetching\n",
    "dataSet = 'dataset/nyc_taxi'\n",
    "filePath = dataSet+'.csv'\n",
    "df = pd.read_csv(filePath, header=0, skiprows=[1,2], names=['time', 'data', 'timeofday', 'dayofweek'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numLags = 100\n",
    "predictionStep = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize data by subtracting mean and dividing by std\n",
    "meanSeq = np.mean(df['data'])\n",
    "stdSeq = np.std(df['data'])\n",
    "df['data'] = (df['data'] - meanSeq)/stdSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeEmbeddedMatrix(sequence, numLags=100, predictionStep=1):\n",
    "  print(\"generate time embedded matrix\")\n",
    "  inDim = numLags\n",
    "  X_train = np.zeros(shape=(len(sequence), inDim))\n",
    "  y_train = np.zeros(shape=(len(sequence), 1))\n",
    "  for i in range(numLags-1, len(sequence)-predictionStep):\n",
    "    X_train[i, :] = np.array(sequence['data'][(i-numLags+1):(i+1)])\n",
    "    y_train[i, :] = sequence['data'][i+predictionStep]\n",
    "  print('input shape: ',X_train.shape)\n",
    "  print('target shape: ',y_train.shape)\n",
    "  return (X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate time embedded matrix\n",
      "input shape:  (17520, 100)\n",
      "target shape:  (17520, 1)\n"
     ]
    }
   ],
   "source": [
    "X, y = getTimeEmbeddedMatrix(df, numLags, predictionStep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14016, 100) (14016, 1) (3504, 100) (3504, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\n",
    "train = (X_train,y_train)\n",
    "test = (X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running for 5 iterations\n",
      "> Hidden size unit 100\n"
     ]
    }
   ],
   "source": [
    "num_iterations_ = 5\n",
    "hidden_unit = 100\n",
    "model = 'GRU' \n",
    "print(\"> Running for\", num_iterations_,\"iterations\")\n",
    "print(\"> Hidden size unit\", hidden_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_cell(object):\n",
    "\n",
    "    def __init__(self, input_nodes, hidden_unit, output_nodes):\n",
    "\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_unit = hidden_unit\n",
    "        self.output_nodes = output_nodes\n",
    "        self.Wx = tf.Variable(tf.zeros([self.input_nodes, self.hidden_unit]))\n",
    "\n",
    "        self.Wr = tf.Variable(tf.zeros([self.input_nodes, self.hidden_unit]))\n",
    "        self.br = tf.Variable(tf.compat.v1.truncated_normal([self.hidden_unit], mean=1))\n",
    "        \n",
    "        self.Wz = tf.Variable(tf.zeros([self.input_nodes, self.hidden_unit]))\n",
    "        self.bz = tf.Variable(tf.compat.v1.truncated_normal([self.hidden_unit], mean=1))\n",
    "\n",
    "        self.Wh = tf.Variable(tf.zeros([self.hidden_unit, self.hidden_unit]))\n",
    "\n",
    "        self.Wo = tf.Variable(tf.compat.v1.truncated_normal([self.hidden_unit, self.output_nodes], mean=1, stddev=.01))\n",
    "        self.bo = tf.Variable(tf.compat.v1.truncated_normal([self.output_nodes], mean=1, stddev=.01))\n",
    "\n",
    "        self._inputs = tf.compat.v1.placeholder(tf.float32,shape=[self.input_nodes,self.hidden_unit], name='inputs')\n",
    "        batch_input_ = tf.transpose(self._inputs, perm=[ 0, 1])\n",
    "        self.processed_input = tf.transpose(batch_input_)\n",
    "        self.initial_hidden = self._inputs\n",
    "        self.initial_hidden = tf.matmul(tf.transpose(self.initial_hidden), tf.zeros([input_nodes, hidden_unit])) \n",
    "\n",
    "    def Gru(self, previous_hidden_state, x):\n",
    "        x = self._inputs\n",
    "        print(\"x shape\",x.shape)\n",
    "        print(previous_hidden_state , 'hidden state')\n",
    "        z = tf.sigmoid(tf.matmul(tf.transpose(x), self.Wz) + self.bz)\n",
    "        r = tf.sigmoid(tf.matmul(tf.transpose(x), self.Wr) + self.br)\n",
    "        h_ = tf.tanh(tf.matmul(tf.transpose(x), self.Wx) +\n",
    "                     tf.matmul(previous_hidden_state, self.Wh) * r)\n",
    "\n",
    "        current_hidden_state = tf.multiply( (1 - z), h_) + tf.multiply(previous_hidden_state, z)\n",
    "\n",
    "        return current_hidden_state\n",
    "\n",
    "    def get_states(self):\n",
    "        all_hidden_states = tf.scan(self.Gru, self.processed_input, initializer=self.initial_hidden, name='states')\n",
    "        return all_hidden_states\n",
    "\n",
    "    def get_output(self, hidden_state):\n",
    "        print(\"inside output\")\n",
    "        output = tf.nn.relu(tf.matmul(hidden_state, self.Wo) + self.bo)\n",
    "        return output\n",
    "\n",
    "    def get_outputs(self):\n",
    "        all_hidden_states = self.get_states()\n",
    "        all_outputs = tf.map_fn(self.get_output, all_hidden_states)\n",
    "        return all_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(x, y, batch_size=101):\n",
    "    perm = np.random.permutation(len(x))\n",
    "    x = x[perm]\n",
    "    y = y[perm]\n",
    "\n",
    "    batch_x = np.array_split(x, len(x) / batch_size)\n",
    "    batch_y = np.array_split(y, len(y) / batch_size)\n",
    "    \n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(train, test, hidden_unit, alpha=learning_rate, isTrain=False, num_iterations=num_iterations, batch_size=100):\n",
    "    np.random.seed(seed)\n",
    "    tf.compat.v1.set_random_seed(seed)\n",
    "    (trainX, trainY) = train\n",
    "    (testX, testY) = test\n",
    "    (n_x, m) = trainX.T.shape\n",
    "\n",
    "    Y = tf.compat.v1.placeholder(tf.float32, shape=[None, output_nodes], name='inputs')\n",
    "    print(\"Calling GRU cell\")\n",
    "    rnn = GRU_cell(input_nodes, hidden_unit, output_nodes)\n",
    "    print(\"Calling get outputs\")\n",
    "    outputs = rnn.get_outputs()\n",
    "    print(\"outside get output\")\n",
    "    prediction = tf.nn.softmax(outputs[-1])\n",
    "\n",
    "    cost = -tf.reduce_sum(Y * tf.compat.v1.log(prediction))\n",
    "    saver = tf.compat.v1.train.Saver(max_to_keep=10)\n",
    "\n",
    "    optimizer = tf.compat.v1.train.GradientDescentOptimizer(alpha).minimize(cost)\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "    accuracy = (tf.reduce_mean(tf.cast(correct_prediction, tf.float32))) * 100\n",
    "\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "    sess = tf.compat.v1.Session()\n",
    "    sess.run(init)\n",
    "\n",
    "    if not os.path.isdir(os.getcwd() + weights_folder):\n",
    "        print('Missing folder made')\n",
    "        os.makedirs(os.getcwd() + weights_folder)\n",
    "\n",
    "    if isTrain:\n",
    "        num_minibatches = len(trainX) / batch_size\n",
    "        for iteration in range(num_iterations):\n",
    "            iter_cost = 0.\n",
    "            print(trainX.shape,trainY.shape,'x,y shape')\n",
    "            (batch_x, batch_y) = create_batches(trainX, trainY, batch_size=batch_size)\n",
    "            \n",
    "            for (minibatch_X, minibatch_Y) in zip(batch_x, batch_y):\n",
    "                print(minibatch_X.shape,minibatch_Y.shape)\n",
    "              #  minibatch_X = minibatch_X.reshape(1,10100 )\n",
    "                minibatch_Y = minibatch_Y.reshape((-1,1,101))\n",
    "                print(minibatch_X.shape,rnn._inputs.shape)\n",
    "                _, minibatch_cost, acc = sess.run([optimizer, cost, accuracy], feed_dict={rnn._inputs: minibatch_X, Y: minibatch_Y})\n",
    "                iter_cost += minibatch_cost*1.0 / num_minibatches\n",
    "\n",
    "            print(\"Iteration {iter_num}, Cost: {cost}, Accuracy: {accuracy}\".format(iter_num=iteration, cost=iter_cost, accuracy=acc))\n",
    "\n",
    "        # print ppretty(rnn)\n",
    "        Train_accuracy = str(sess.run(accuracy, feed_dict={rnn._inputs: trainX, Y: trainY}))\n",
    "        # Test_accuracy = str(sess.run(accuracy, feed_dict={rnn._inputs: testX, Y: testY}))\n",
    "\n",
    "        save_path = saver.save(sess, \".\" + weights_folder + \"model_\" + model + \"_\" + str(hidden_unit) + \".ckpt\")\n",
    "        print(\"Parameters have been trained and saved!\")\n",
    "        print(\"\\rTrain Accuracy: %s\" % (Train_accuracy))\n",
    "\n",
    "    else:  # test mode\n",
    "        # no need to download weights in this assignment\n",
    "        # check_download_weights(model, hidden_unit)\n",
    "\n",
    "        saver.restore(sess, \".\" + weights_folder + \"model_\" + model + \"_\" + str(hidden_unit) + \".ckpt\")\n",
    "        acc = sess.run(accuracy, feed_dict={rnn._inputs: testX, Y: testY})\n",
    "        print(\"Test Accuracy:\"+\"{:.3f}\".format(acc))\n",
    "\n",
    "    sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling GRU cell\n",
      "Calling get outputs\n",
      "x shape (101, 100)\n",
      "Tensor(\"placeholder_1:0\", shape=(100, 100), dtype=float32) hidden state\n",
      "inside output\n",
      "outside get output\n",
      "(14016, 100) (14016, 1) x,y shape\n",
      "(101, 100) (101, 1)\n",
      "(101, 100) (101, 100)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 1, 101) for Tensor 'inputs_20:0', which has shape '(None, 101)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-7904ea77f4cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misTrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_iterations_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_unit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_unit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-43-42dd6ebeb0b1>\u001b[0m in \u001b[0;36mSGD\u001b[1;34m(train, test, hidden_unit, alpha, isTrain, num_iterations, batch_size)\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[0mminibatch_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminibatch_Y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m101\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                 \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminibatch_cost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mminibatch_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mminibatch_Y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m                 \u001b[0miter_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mminibatch_cost\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnum_minibatches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1154\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1156\u001b[1;33m                 (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1157\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (1, 1, 101) for Tensor 'inputs_20:0', which has shape '(None, 101)'"
     ]
    }
   ],
   "source": [
    " SGD(train, test, isTrain=True, num_iterations=num_iterations_, hidden_unit = hidden_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
