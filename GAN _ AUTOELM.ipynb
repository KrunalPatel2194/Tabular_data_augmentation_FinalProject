{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "#from optparse import OptionParser\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import random\n",
    "import pandas as pd\n",
    "from numpy.linalg import pinv\n",
    "from numpy.linalg import inv\n",
    "random.seed(0)\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set hyper-parameters for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numLags = 100\n",
    "predictionStep = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>data</th>\n",
       "      <th>timeofday</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-07-01 00:00:00</td>\n",
       "      <td>10844</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-01 00:30:00</td>\n",
       "      <td>8127</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-07-01 01:00:00</td>\n",
       "      <td>6210</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-01 01:30:00</td>\n",
       "      <td>4656</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-07-01 02:00:00</td>\n",
       "      <td>3820</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time   data  timeofday  dayofweek\n",
       "0  2014-07-01 00:00:00  10844          0          1\n",
       "1  2014-07-01 00:30:00   8127         30          1\n",
       "2  2014-07-01 01:00:00   6210         60          1\n",
       "3  2014-07-01 01:30:00   4656         90          1\n",
       "4  2014-07-01 02:00:00   3820        120          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet = '../nyc_taxi'\n",
    "filePath = dataSet+'.csv'\n",
    "df = pd.read_csv(filePath, header=0, skiprows=[1,2], names=['time', 'data', 'timeofday', 'dayofweek'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17520 entries, 0 to 17519\n",
      "Data columns (total 4 columns):\n",
      "time         17520 non-null object\n",
      "data         17520 non-null int64\n",
      "timeofday    17520 non-null int64\n",
      "dayofweek    17520 non-null int64\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 547.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time         0\n",
       "data         0\n",
       "timeofday    0\n",
       "dayofweek    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                              # standardize data by subtracting mean and dividing by std\n",
    "  meanSeq = np.mean(df['data'])\n",
    "  stdSeq = np.std(df['data'])\n",
    "  df['data'] = (df['data'] - meanSeq)/stdSeq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare input-target pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate time embedded matrix\n",
      "input shape:  (17520, 100)\n",
      "target shape:  (17520, 1)\n"
     ]
    }
   ],
   "source": [
    "def getTimeEmbeddedMatrix(sequence, numLags=100, predictionStep=1):\n",
    "  print(\"generate time embedded matrix\")\n",
    "  inDim = numLags\n",
    "  X = np.zeros(shape=(len(sequence), inDim))\n",
    "  T = np.zeros(shape=(len(sequence), 1))\n",
    "  for i in range(numLags-1, len(sequence)-predictionStep):\n",
    "    X[i, :] = np.array(sequence['data'][(i-numLags+1):(i+1)])\n",
    "    T[i, :] = sequence['data'][i+predictionStep]\n",
    "  print('input shape: ',X.shape)\n",
    "  print('target shape: ',T.shape)\n",
    "  return (X, T)\n",
    "\n",
    "(X, T) = getTimeEmbeddedMatrix(df, numLags, predictionStep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17520, 100) (17520, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOELM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: (25, 100)\n",
      "bias: (1, 25)\n",
      "input features: (1, 100)\n",
      "[[26.73015071 27.98622253 29.20842738 25.69226713 29.06920576 25.30993178\n",
      "  24.07201064 24.31074231 28.16047585 27.52178154 27.86130065 28.58902652\n",
      "  27.49881974 29.0730478  26.64207791 29.25626895 28.32753515 24.11616073\n",
      "  27.50254857 25.18363982 24.77184242 26.32346954 28.48496744 27.26313313\n",
      "  25.02408901]]\n",
      "hidden (before nonlinear activation): (1, 25)\n",
      "hidden (after nonlinear activateion): (1, 25)\n",
      "hidden (after nonlinear activateion): (1, 25)\n"
     ]
    }
   ],
   "source": [
    "weights = np.random.random((25,100))                                    # initialize weights\n",
    "print('weights:',weights.shape)\n",
    "\n",
    "bias = np.random.random((1,25)) * 2 -1                                   # initialize biases\n",
    "print('bias:', bias.shape)\n",
    "\n",
    "features = np.random.random((1,100))                                     # initialize features\n",
    "print('input features:', features.shape)\n",
    "\n",
    "def linear(features,weights,bias):\n",
    "    print(np.dot(features, np.transpose(weights))  + bias)\n",
    "    return np.dot(features, np.transpose(weights)) #+ bias\n",
    "\n",
    "hidden = linear(features,weights,bias)                                  # linear lyout\n",
    "print('hidden (before nonlinear activation):', hidden.shape)\n",
    "\n",
    "def sigmoidActFunc(features):                                           # sigmoid function for features\n",
    "  return 1.0 / (1.0 + np.exp(-features))\n",
    "\n",
    "hidden = sigmoidActFunc(hidden)                                         # sigmoid function for hidden layer\n",
    "print('hidden (after nonlinear activateion):', hidden.shape)\n",
    " \n",
    "def reluActFunc(features):                                              # initialize weights relu layer for features\n",
    "  return np.maximum(0,features)\n",
    "hidden = reluActFunc(hidden)\n",
    "print('hidden (after nonlinear activateion):', hidden.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nDimInput = 100\n",
    "nDimOutput = 100\n",
    "numNeurons = 25\n",
    "lamb=0.0001\n",
    "outputWeightFF = 0.92 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total initial:  249975\n",
      "total sequential:  0\n"
     ]
    }
   ],
   "source": [
    "                                                               # comment these two lines when you want to alter things\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, T, test_size=0.2)\n",
    "border = int(9999 * numNeurons)\n",
    "x_train_init = X_train[:border]                                # it was 6250 before\n",
    "x_train_seq = X_train[border:]                                 # was 7766 before\n",
    "\n",
    "print('total initial: ', (border))\n",
    "print('total sequential: ', len(x_train_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUTOELM implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "class AUTOELM(object):\n",
    "    \n",
    "    # initialize parameters like weights and biases for initial training phase\n",
    "    def __init__(self, inputs, outputs, numHiddenNeurons, forgettingFactor=0.999):\n",
    "        self.name = 'AUTOELM'\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.numHiddenNeurons = numHiddenNeurons\n",
    "\n",
    "        # input to hidden weights\n",
    "        self.inputWeights = None\n",
    "        # bias of hidden units\n",
    "        self.bias = None\n",
    "        # hidden to output layer connection\n",
    "        self.beta = None\n",
    "        # auxiliary matrix used for sequential learning\n",
    "        self.M = None\n",
    "\n",
    "        self.forgettingFactor = forgettingFactor\n",
    "        self.bf= None\n",
    "        self.k = None\n",
    "        self.mask = None\n",
    "\n",
    "    # calculating hidden layer activation\n",
    "    def calculateHiddenLayerActivation(self, features):\n",
    "        print('features',features.shape,'wieghts',self.inputWeights,'bias',self.bias)\n",
    "        V = (np.dot(features, np.transpose(self.inputWeights))  + self.bias)\n",
    "        #H = sigmoidActFunc(V)\n",
    "        print(V)\n",
    "        H = reluActFunc(V)\n",
    "        print(H.shape,H)\n",
    "        return H\n",
    "\n",
    "\n",
    "    # calculate initialize phase\n",
    "    def initializePhase(self, lamb=0.0001):\n",
    "        \"\"\"\n",
    "        Step 1: Initialization phase\n",
    "        \"\"\"\n",
    "        # randomly initialize the input->hidden connections\n",
    "        self.inputWeights = np.random.random((self.inputs, self.numHiddenNeurons))\n",
    "        self.bf = np.random.random()                                                     # initialize bf\n",
    "        self.inputWeights = self.inputWeights * 2 - 1                                    # input weights\n",
    "        self.bias = np.random.random((self.numHiddenNeurons)) * 2 - 1                    # bias\n",
    "        # auxiliary matrix used for sequential learning\n",
    "        self.M = inv(lamb*np.eye(self.numHiddenNeurons))                                 # auxiliary matrix\n",
    "        # hidden to output layer connection\n",
    "        self.beta = np.zeros([self.numHiddenNeurons,self.outputs])\n",
    "        self.k = np.zeros([self.numHiddenNeurons,self.numHiddenNeurons])\n",
    "    \n",
    "    def init_training(self , features, targets):\n",
    "        H = np.dot(self.inputs, self.inputWeights) + self.bias\n",
    "        H = 1/(1+np.exp(-H))                                                             # sigmoid activation function\n",
    "        HT = np.transpose(H)\n",
    "        I = np.identity(self.numHiddenNeurons)\n",
    "        C_I = I\n",
    "        HTH = np.dot(HT, H)\n",
    "        K = C_I + HTH                                                                    # K\n",
    "        self.k = K \n",
    "        inverse_k = np.linalg.inv(K)                                                     # inverse K\n",
    "        H_inverse = np.dot(inverse_k,HT)                                                 # inverse H\n",
    "        sin_y = np.sin(self.outputs)                                                     # sin y\n",
    "        arcsin_y = np.arcsin(sin_y)\n",
    "        inverse_acti_y = arcsin_y                                                        # inverse activation y\n",
    "        An = np.dot(H_inverse, inverse_acti_y)\n",
    "        AnHf = np.dot(H,An)\n",
    "        #Bn = mean_squared_error(AnHf,inverse_acti_y)\n",
    "        Bn = np.square(np.subtract(AnHf,inverse_acti_y)).mean()                          # Bias Bn\n",
    "        Bn = np.sqrt(Bn)\n",
    "        self.beta = An                                                                   # Beta\n",
    "        init_train = Bn\n",
    "        print(\"init training complete!\")\n",
    "        return init_train\n",
    "    \n",
    "    def seq_train(self, features, targets, mask):\n",
    "        self.inputWeights = np.transpose(self.beta)                                 # assigns beta weights to alpha \n",
    "        H = np.dot(features, self.inputWeights) + self.bf\n",
    "        H = 1/(1+np.exp(-H)) \n",
    "        HT = np.transpose(H)                                                        # transpose of H\n",
    "        HTH = np.dot(HT, H)\n",
    "        K = self.k + HTH\n",
    "        self.k = K\n",
    "                                                                                     #addition\n",
    "        K_dirty = K + 0.00001*np.random.rand(25, 25)\n",
    "        # * #\n",
    "        K_inverse = np.linalg.inv(K_dirty)\n",
    "        sin_y = np.sin(self.outputs)\n",
    "        arcsin_y = np.arcsin(sin_y)\n",
    "        inverse_acti_y = arcsin_y\n",
    "        UPDATE = np.dot(np.dot(K_inverse, HT), inverse_acti_y - np.dot(H, self.beta))  # [D x m]    \n",
    "        ###############################multiplication with mask  makes it zero ############3\n",
    "        #UPDATE = np.dot(mask, UPDATE)\n",
    "        ###############################multiplication with mask  makes it zero ############3\n",
    "        An = self.beta + UPDATE                                                       # An\n",
    "        self.beta = An\n",
    "        AnHf = np.dot(H, An)\n",
    "        Bn = np.square(np.subtract(AnHf,inverse_acti_y)).mean()                       # Bn\n",
    "        Bn = np.sqrt(Bn)\n",
    "        self.bf = Bn\n",
    "        seq_train =  Bn\n",
    "        return seq_train\n",
    "    \n",
    "    def retrieve_beta(self):\n",
    "        return self.beta\n",
    "    \n",
    "    def predict(self, features):\n",
    "        \"\"\"\n",
    "        Make prediction with feature matrix\n",
    "        :param features: feature matrix with dimension (numSamples, numInputs)\n",
    "        :return: predictions with dimension (numSamples, numOutputs)\n",
    "        \"\"\"\n",
    "       # tf.matmul(self.__activation(tf.matmul(self.__x, self.inputWeights) + self.__bf), self.__beta)\n",
    "        H = (np.dot(features,self.inputWeights) + self.bf)\n",
    "        H = 1/(1+np.exp(-H))\n",
    "        H = np.dot(H,self.beta)\n",
    "        prediction = H\n",
    "        return prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perform_sequential_training(train_set, auto_elm, epochs, x_seq_train, batch_size, h_nodes, number_neurons, flag):\n",
    "    neuron = random.randint(0, h_nodes - 1)                                       # select initial hidden neuron\n",
    "    mask = np.zeros([h_nodes, h_nodes])                                           # mask of hidden neuron dimensions\n",
    "    mask[neuron,neuron] = 1                                      # add a single digit to a row (corresponds to single neuron)\n",
    "                                    # mask = np.eye(256) # update all nodes\n",
    "    group = 1                                              # group of data\n",
    "    count = train_set #                                         number of training data\n",
    "\n",
    "                                                               # actual network training phase\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, len(x_seq_train), batch_size):\n",
    "            x_batch = x_seq_train[i:i+batch_size]\n",
    "            auto_elm.seq_train(x_batch, x_batch, mask)\n",
    "        \n",
    "                                                                # fetch the node beta weight data\n",
    "        node = auto_elm.retrieve_beta()[neuron]\n",
    "    \n",
    "    print(\"Neuron Used: {}\\n\".format(neuron))\n",
    "    print(\"sequential training complete!\")\n",
    "    return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# added for beta weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init training complete!\n",
      "Neuron Used: 12\n",
      "\n",
      "sequential training complete!\n",
      "augmented data X shape (1411200, 100) (14400, 100)\n",
      "augmented data Y shape (305760, 1) (3120, 1)\n"
     ]
    }
   ],
   "source": [
    "auto_elm = AUTOELM(inputs=nDimInput,outputs=nDimOutput, numHiddenNeurons=numNeurons,forgettingFactor=outputWeightFF)\n",
    "auto_elm.initializePhase(lamb=lamb)                     # initialize phase\n",
    "encoding_0 = auto_elm.init_training(x_train_init,x_train_init)\n",
    "decoding_0 = perform_sequential_training(10,auto_elm,20,x_train_seq,50,numNeurons,0,False)\n",
    "\n",
    "                                                        # Block added here for using Beta values to generate more training data\n",
    "thr = 1200 * 12                                         # NB_YEARS * 12 (months)\n",
    "\n",
    "x_train_temp1 = X[:thr]\n",
    "y_train_temp1 = T[thr:]\n",
    "\n",
    "x_test1 = X[:thr]\n",
    "y_test1 = T[thr:]\n",
    "\n",
    "\n",
    "nb_copies = 98\n",
    "X_train_fake = np.concatenate([\n",
    "    x_train_temp1\n",
    "    + 5 * decoding_0 - 5                                        # global offset with a (possibly large) scalar\n",
    "    + 2 * np.random.random(x_train_temp1.shape) - 1             # small element-wise offset\n",
    "    for _ in range(nb_copies)\n",
    "])\n",
    "y_train_fake = np.concatenate([\n",
    "    y_train_temp1\n",
    "    for _ in range(nb_copies)\n",
    "])\n",
    "\n",
    "\n",
    "print('augmented data X shape',X_train_fake.shape, x_test1.shape)\n",
    "print('augmented data Y shape',y_train_fake.shape, y_test1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1411200, 100) (305760, 1)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot                                 # plotting a graph\n",
    "print(X_train_fake.shape,y_train_fake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.scatter(X_train_fake[:,50],X_train_fake[:,99])         # scatter plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.36643425, -5.47800951, -4.95099628, ..., -4.74536291,\n",
       "        -5.54385588, -4.89056993],\n",
       "       [-4.52748055, -4.20886365, -5.37253727, ..., -4.35626906,\n",
       "        -4.49364812, -5.86213713],\n",
       "       [-4.30291199, -5.56449149, -4.41870218, ..., -4.55702483,\n",
       "        -4.70675942, -5.38280171],\n",
       "       ...,\n",
       "       [-3.62876255, -3.81330006, -2.74922147, ..., -5.08613201,\n",
       "        -5.38798928, -5.18210364],\n",
       "       [-3.45659555, -3.52899644, -2.77820194, ..., -5.17609908,\n",
       "        -4.94575434, -4.92736219],\n",
       "       [-3.531641  , -3.15258746, -3.77792885, ..., -4.60287278,\n",
       "        -5.92703847, -5.10652236]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14016, 100)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5362914891867696"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxElement = np.amax(X_train)\n",
    "maxElement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import hstack\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():                       # Defining 1D discriminator model with two input 1 output\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25, activation='relu', kernel_initializer='he_uniform', input_dim = 2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(latent_dim, outputs=2):              # Defining 1D generator model with two outputs\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, activation='relu', kernel_initializer='he_uniform', input_dim=latent_dim))\n",
    "    model.add(Dense(outputs, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "def discriminator_loss(real_output, fake_output):                 # Defining 1D discriminator Loss function\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss3\n",
    "def generator_loss(fake_output):                                 # Defining 1D generator Loss function\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GAN(generator, discriminator):                               # Defining GAN model\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14016, 100)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(n = 1401600):                             # generating real samples\n",
    "    X1 = (X_train - 4) * -0.5\n",
    "    X2 = np.sqrt(X1)\n",
    "    X1 = X1.reshape(n, 1)\n",
    "    X2 = X2.reshape(n, 1)\n",
    "    X = hstack((X1, X2))\n",
    "                                                                    # generate class labels\n",
    "    y = ones((n, 1))\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1,y1 =generate_real_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.36643425, -5.47800951, -4.95099628, ..., -4.74536291,\n",
       "        -5.54385588, -4.89056993],\n",
       "       [-4.52748055, -4.20886365, -5.37253727, ..., -4.35626906,\n",
       "        -4.49364812, -5.86213713],\n",
       "       [-4.30291199, -5.56449149, -4.41870218, ..., -4.55702483,\n",
       "        -4.70675942, -5.38280171],\n",
       "       ...,\n",
       "       [-3.62876255, -3.81330006, -2.74922147, ..., -5.08613201,\n",
       "        -5.38798928, -5.18210364],\n",
       "       [-3.45659555, -3.52899644, -2.77820194, ..., -5.17609908,\n",
       "        -4.94575434, -4.92736219],\n",
       "       [-3.531641  , -3.15258746, -3.77792885, ..., -4.60287278,\n",
       "        -5.92703847, -5.10652236]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                        # generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n):\n",
    "                                                     #x_input = randn(len(X_train))\n",
    "                                                     # generate points in the latent space\n",
    "    x_input = X_train_fake[:1401600]\n",
    "                                                     #x_input = x_input.reshape(n, latent_dim)\n",
    "    return x_input\n",
    "\n",
    "                                                            # use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n):\n",
    "                                                                  # generate points in latent space\n",
    "    x_input = generate_latent_points(latent_dim, n)\n",
    "                                                                  # predict outputs\n",
    "    X = generator.predict(x_input)\n",
    "                                                                  # create class labels\n",
    "    y = zeros((len(X), 1))\n",
    "    return X, y\n",
    "\n",
    "                                                                # evaluate the discriminator and plot real and fake points\n",
    "def summarize_performance(epoch, generator, discriminator, latent_dim, n=1401600 ):\n",
    "                                                                # prepare real samples\n",
    "    x_real, y_real = generate_real_samples(n)\n",
    "                                                                # evaluate discriminator on real examples\n",
    "    _, acc_real = discriminator.evaluate(x_real, y_real, verbose=0)\n",
    "                                                                # prepare fake examples\n",
    "    x_fake, y_fake = generate_fake_samples(generator, latent_dim, n)\n",
    "                                                                # evaluate discriminator on fake examples\n",
    "    _, acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n",
    "                                                                # summarize discriminator performance\n",
    "    print(epoch, acc_real, acc_fake)\n",
    "                                                                # scatter plot real and fake data points\n",
    "    pyplot.scatter(x_real[:, 0], x_real[:, 1], color='red')\n",
    "    pyplot.scatter(x_fake[:, 0], x_fake[:, 1], color='blue')\n",
    "    pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                      # train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, latent_dim, n_epochs=5000, n_batch=1401600 , n_eval=100):\n",
    "                                                        # determine half the size of one batch, for updating the discriminator\n",
    "    half_batch = int(n_batch)\n",
    "                                                                        # manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "                                                                         # prepare real samples\n",
    "        x_real, y_real = generate_real_samples(half_batch)\n",
    "                                                                         # prepare fake examples\n",
    "        x_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "                                                                            # update discriminator\n",
    "        d_model.train_on_batch(x_real, y_real)\n",
    "        d_model.train_on_batch(x_fake, y_fake)\n",
    "                                                                     # prepare points in latent space as input for the generator\n",
    "        x_gan = generate_latent_points(latent_dim, n_batch)\n",
    "                                                                             # create inverted labels for the fake samples\n",
    "        y_gan = ones((n_batch, 1))\n",
    "                                                                      # update the generator via the discriminator's error\n",
    "        gan_model.train_on_batch(x_gan, y_gan)\n",
    "                                                                            # evaluate the model every n_eval epochs\n",
    "        if (i+1) % n_eval == 0:\n",
    "            summarize_performance(i, g_model, d_model, latent_dim)\n",
    "\n",
    "                                                                                 # size of the latent space\n",
    "latent_dim = 100\n",
    "                                                                                # create the discriminator\n",
    "discriminator = discriminator()\n",
    "                                                                            # create the generator\n",
    "generator = generator(latent_dim)\n",
    "                                                                              # create the gan\n",
    "gan_model = GAN(generator, discriminator)\n",
    "                                                                            # train model\n",
    "from datetime import datetime\n",
    "                                                                          # datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "print(\"training started\" ,dt_string)\n",
    "train(generator, discriminator, gan_model, latent_dim)\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "print(\"training ended\" ,dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
